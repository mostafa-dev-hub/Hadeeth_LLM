{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxoDcqOdr_LE",
        "outputId": "c90adc66-143c-462c-dc13-169c096ff67d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.20-py3-none-any.whl.metadata (659 bytes)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.23 (from langchain_community)\n",
            "  Downloading langchain_core-0.2.24-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
            "  Downloading langsmith-0.1.93-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Collecting openai<2.0.0,>=1.32.0 (from langchain-openai)\n",
            "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.1)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.8.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.30.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.27.0 (from chromadb)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.23->langchain_community)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting importlib-metadata<=8.0.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (71.0.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.23.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain_community)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Downloading langchain_community-0.2.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.1.19-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.20-py3-none-any.whl (5.0 kB)\n",
            "Downloading chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.2.11-py3-none-any.whl (990 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m394.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.24-py3-none-any.whl (377 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.93-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.37.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=1e3a1051aa6c9baf60a2575917c7dc91051c583535812ffa0e09c8f1b628175a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, types-requests, python-multipart, python-dotenv, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, marshmallow, jsonpointer, importlib-metadata, humanfriendly, httptools, h11, dnspython, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, langchainhub, jsonpatch, httpcore, email_validator, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, langsmith, kubernetes, httpx, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation-asgi, openai, langchain-core, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, fastapi, langchain, chromadb, langchain_community\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.1.0\n",
            "    Uninstalling importlib_metadata-8.1.0:\n",
            "      Successfully uninstalled importlib_metadata-8.1.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 chroma-hnswlib-0.7.6 chromadb-0.5.5 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecated-1.2.14 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-8.0.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-30.1.0 langchain-0.2.11 langchain-core-0.2.24 langchain-openai-0.1.19 langchain-text-splitters-0.2.2 langchain_community-0.2.10 langchainhub-0.1.20 langsmith-0.1.93 marshmallow-3.21.3 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.18.1 openai-1.37.1 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-instrumentation-0.47b0 opentelemetry-instrumentation-asgi-0.47b0 opentelemetry-instrumentation-fastapi-0.47b0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-util-http-0.47b0 orjson-3.10.6 overrides-7.7.0 posthog-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 python-multipart-0.0.9 starlette-0.37.2 tiktoken-0.7.0 types-requests-2.32.0.20240712 typing-inspect-0.9.0 uvicorn-0.30.3 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured"
      ],
      "metadata": {
        "id": "VFNuyhz70Bxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e407f442-e046-466c-fb65-ede20c433e42",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured\n",
            "  Downloading unstructured-0.15.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.7)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.25.2)\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.2)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.24.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.9.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2024.7.4)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client->unstructured)\n",
            "  Downloading deepdiff-7.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.27.0)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (24.1)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
            "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client->unstructured)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
            "Downloading unstructured-0.15.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading rapidfuzz-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.24.1-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=1a4e1b3fd5aa648b3ea7c7a9585dcc37f4e95090760f3c8eb55ae4ae5612e5ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, pypdf, ordered-set, langdetect, jsonpath-python, emoji, requests-toolbelt, deepdiff, unstructured-client, unstructured\n",
            "Successfully installed deepdiff-7.0.1 emoji-2.12.1 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 ordered-set-4.1.0 pypdf-4.3.1 python-iso639-2024.4.27 python-magic-0.4.27 rapidfuzz-3.9.4 requests-toolbelt-1.0.0 unstructured-0.15.0 unstructured-client-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY'] = 'Lang_Chain_API_KEY'"
      ],
      "metadata": {
        "id": "xQYQcaQssV2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WKWHwJ9R-0P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = 'OPEN_AI_API_KEY'"
      ],
      "metadata": {
        "id": "XA09JAAqsYWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCDbb3p5xMCg",
        "outputId": "e74f4b3d-0233-404f-9791-ce11dd3d4069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: read a excel file and combine two columns in one line on a txt file (two texts in one text)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read the Excel file\n",
        "df = pd.read_excel('/content/drive/MyDrive/WB.xlsx')  # Replace \"your_file.xlsx\" with the actual file name\n",
        "\n",
        "\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "w1ZX-w3Oquhd",
        "outputId": "d6fef81d-59c0-4c44-af66-56602e20ff3c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/WB.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c0af3b6cbdf6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Read the Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/WB.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace \"your_file.xlsx\" with the actual file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1494\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1497\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/WB.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the two columns you want to combine are named \"Column1\" and \"Column2\"\n",
        "combined_text = \"\"\n",
        "for index, row in df.iterrows():\n",
        "    combined_text +=  \" الحديث: \"+str(row[\"hadith_text\"] ) +\" \\n\" + \" الشرح: \" + str(row[\"explanation\"])+ \"\\n\"\n",
        "\n",
        "# print(combined_text)\n",
        "\n",
        "# Write the combined text to a txt file /content/drive/MyDrive/\n",
        "with open('hadeeth_ds_final_file.txt', \"w\", encoding='utf-8') as f:\n",
        "    f.write(combined_text)"
      ],
      "metadata": {
        "id": "cIhwlg50xTHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "yW_MyyQmw3q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "#Load\n",
        "loader = TextLoader(\"hadeeth_ds_final_file.txt\") #replace with your file\n",
        "docs = loader.load()\n",
        "\n",
        "#Split\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "#Embed\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n"
      ],
      "metadata": {
        "id": "J__myK1qwy2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "#Prompt\n",
        "template=\"\"\"استخدم الأجزاء التالية من السياق المتكونة من حديث و شرح  للإجابة على السؤال التالي في النهاية\n",
        "احرص على ان تكون كلامات اجابتك متواجدة في نص الحديث او شرحه.\n",
        ".ستند الى السياق جيدا\n",
        ".قد تكون الاجابة تكملتا للسياق او متضمنة في معناه . اذكر الحديث او النص اذا انطلب في السؤال\n",
        "إذا كنت لا تعرف الإجابة، قل فقط أنك لا تعرف، ولا تحاول اختلاق إجابة.\n",
        "اجعل الإجابة مختصرة و موجزة قدر الإمكان. قل دائمًا \"شكرًا على السؤال!\" في نهاية الجواب.\n",
        "السياق: {context}\n",
        "السؤال: {question}\n",
        "الجواب المفيد:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "#Format String\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs) ## Ask is it joining all docs in one string ?\n",
        "\n",
        "\n",
        "#LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "#Chain\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} ## context to search the answer from\n",
        "    ## ask where if the parameter of the format_docs() method ?\n",
        "    | prompt ## Ask better\n",
        "    | llm ## specify the llm we use\n",
        "    | StrOutputParser() ## the format of the output\n",
        ")\n",
        "\n",
        "#Question\n",
        "question = input(\"ادخل سؤالك:\")\n",
        "rag_chain.invoke(question)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "XxcL6mgw3fgT",
        "outputId": "da4b59a8-58d4-4f40-ca68-89e75e33682b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ادخل سؤالك:ydgfdyugcf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'أعتذر، لا أستطيع الإجابة على هذا السؤال بناءً على السياق المقدم. شكرًا على السؤال!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format_docs(retriever.get_relevant_documents(\"ما فضيلة الاجتماع على ذكر الله؟\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "RVAOXaSR8IjW",
        "outputId": "dcb22c98-0cbb-4533-929e-65d0a85084e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'الشرح: هذا الحديث من الأحاديث التي تدل على فضيلة الاجتماع على ذكر الله -عز وجل-، وهو ما رواه أبو سعيد الخدري عن معاوية -رضي الله عنهما- أنه خرج على حلقة في المسجد فسألهم على أي شيء اجتمعوا، فقالوا: نذكر الله، فاستحلفهم -رضي الله عنه- أنهم ما أرادوا بجلوسهم واجتماعهم إلا الذكر، فحلفوا له، ثم قال لهم: إني لم أستحلفكم تهمة لكم وشكًّا في صدقكم، ولكني رأيت النبي -صلى الله عليه وسلم- خرج على قوم وذكر مثله، وأخبرهم أن الله -عز وجل- يباهي بهم الملائكة، فيقول مثلا: انظروا إلى عبادي اجتمعوا على ذكري، وما أشبه ذلك، مما فيه المباهاة، ولكن ليس هذا الاجتماع أن يجتمعوا على الذكر بصوت واحد، ولكن يذكرون أي شيء يذكرهم بالله -تعالى- من موعظة وذكرى أو يتذكرون نعمة الله عليهم بما أنعم عليهم من نعمة الإسلام وعافية البدن والأمن، وما أشبه ذلك، فإن ذكر نعمة الله من ذكر الله -عز وجل-، فيكون في هذا دليل على فضل جلوس الناس ليتذاكروا نعمة الله عليهم.\\n\\nفهذا الذكر أمر النبي -صلى الله عليه وسلم- أبا بكر أن يقوله إذا أصبح وإذا أمسى وإذا أخذ مضجعه.\\n84 الحديث: عن أبي  سعيد الخدري –رضي الله عنه- قال: خرج معاوية -رضي الله عنه- على حَلْقَةٍ في المسجد، فقال: ما أَجْلَسَكم؟ قالوا: جلسنا نذكر الله، قال: آلله ما أجْلَسَكُم إلا ذاك؟ قالوا: ما أجلسنا إلا ذاك، قال: أما إنّي لم استَحْلِفْكُم تُهْمَةً لكم، وما كان أحد بمنزلتي من رسول الله -صلى الله عليه وسلم- أقَلَّ عنه حديثاً مِنِّي: إنَّ رسول الله -صلى الله عليه وسلم- خَرَجَ على حَلْقَةٍ من أصحابه فقال: «ما أَجْلَسَكم؟» قالوا: جلسنا نذكر الله ونَحْمَدُهُ على ما هَدَانا للإسلام؛ ومَنَّ بِهِ علينا، قال: «آلله ما أجْلَسَكُم إلا ذاك؟» قالوا: والله ما أجلسنا إلا ذاك، قال: «أما إنّي لم أستحلفكم تُهْمَةً لكم، ولكنه أتاني جبريل فأخبرني أن الله يُبَاهِي بكم الملائكة».\\n\\n586 الحديث: عن أبي هريرة -رضي الله عنه- قال: قال رسول الله -صلى الله عليه وسلم-: «ما من قوم يقومون من مجلس لا يذكرون الله -تعالى- فيه، إلا قاموا عن مثل جيفة حمار، وكان لهم حسرة». \\n الشرح: معنى الحديث: أن من جلسوا في مجلس لم يذكروا الله -تعالى- فيه فحالهم كمثل حال الذي يجلس في مائدة ضيافتها جِيفَةُ حمار، التي هي غاية في النتانة والقذارة، ويقوم عن ذلك المجلس كمن يقوم عن هذه الجيفة، وهذا مثال للتفريط في ذكر الله، فيتندمون أشد الندم على ما فرطوا في أوقاتهم وأضاعوها فيما لا نفع فيه. \\nفينبغي على المسلمين: أن يحرصوا كل الحرص على أن تكون مجالسهم طاعة وعبادة وأن يفروا من مجالس اللهو كما يفرون من النتانة والقذارة، فإن الإنسان مسؤول عن أوقاته، ومحاسب عليها، فإن كان خيرًا فخير وإن كان شرًا فشر.\\n587 الحديث: عن جابر-رضي الله عنه- قال: قال رسول الله -صلى الله عليه وسلم-: «ما من مسلم يَغرس غَرسا إلا كان ما أُكل منه له صدقة، وما سُرق منه له صدقة، ولا يَرْزَؤُهُ أحد إلا كان له صدقة».\\n\\nالشرح: هذا الحديث من جملة الأحاديث التي فيها الحث على تقوى الله -تعالى-، بفعل أوامره واجتناب نواهيه، وكان هذا الحديث في آخر أيامه -عليه الصلاة والسلام- عندما خطب الناس في حجة الوداع خطبة بليغة وأوصاهم بوصايا كثيرة وذكرهم بما لهم وعليهم ومن جملة ما جاء فيها تقوى الله -تعالى-، حيث قال: (يا أيها الناس اتقوا ربكم) وهذه كقوله -تعالى-: (يَا أَيُّهَا النَّاسُ اتَّقُوا رَبَّكُمُ)، (النساء: من الآية1)، فأمر الرسول -صلى الله عليه وسلم- الناس جميعا أن يتقوا ربهم الذي خلقهم، وأمدهم بنعم لا تُعدُّ ولا تحصى.\\nوفي الحديث الآخر، عن أبي سعيد الخدري -رضي الله عنه- قال: جاء رجل إلى النبي -صلى الله عليه وسلم-، فقال: يا رسول الله أوصني: قال (عليك بتقوى الله، فإنها جماع كل خير..).\\nوقال -صلى الله عليه وسلم-: (أكثر ما يدخل الناس الجنة تقوى الله وحسن الخلق).\\nوقوله: (وصلوا خمسكم) أي: صلوا الصلوات الخمس التي فرضها الله -عز وجل- على رسوله -صلى الله عليه وسلم-، فإن أول ما يحاسب عليه العبد يوم القيامة صلاته.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Generate 5 similar questions\n",
        "# Multi Query: Different Perspectives\n",
        "template = \"\"\"أنت مساعد نموذج لغة الذكاء الاصطناعي. مهمتك هي لتوليد خمسة\n",
        "إصدارات مختلفة من سؤال المستخدم المحدد لاسترداد المستندات ذات الصلة من المتجه\n",
        "قاعدة البيانات. من خلال توليد وجهات نظر متعددة حول سؤال المستخدم، هدفك هو المساعدة\n",
        "يتغلب المستخدم على بعض القيود المفروضة على بحث التشابه على أساس المسافة.\n",
        "قم بتوفير هذه الأسئلة البديلة مفصولة بأسطر جديدة. السؤال الأصلي: {question}\"\"\"\n",
        "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "generate_queries = ( ## returns 5 questions\n",
        "    prompt_perspectives\n",
        "    | ChatOpenAI(temperature=0)\n",
        "    | StrOutputParser()\n",
        "    | (lambda x: x.split(\"\\n\")) ## splits each question by a new line\n",
        ")\n",
        "\n",
        "print(generate_queries.invoke({\"question\":input(\" ادخل سؤالك\")}))"
      ],
      "metadata": {
        "id": "wearkBG9TySq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c282dee-4ac5-4bfe-8e6c-ddb4e2e1139b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ادخل سؤالكfbvnf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1. ما هي المستندات ذات الصلة بـ \"fbvnf\" في قاعدة البيانات؟', '2. هل هناك أي معلومات متعلقة بـ \"fbvnf\" يمكن العثور عليها في المستندات؟', '3. هل يمكن العثور على أي تفاصيل إضافية حول \"fbvnf\" في الوثائق المخزنة؟', '4. هل هناك أي روابط أو مراجع تشير إلى \"fbvnf\" في المستندات المتاحة؟', '5. هل يمكن العثور على أي تحليل أو تقارير تتعلق بـ \"fbvnf\" في قاعدة البيانات؟']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.load import dumps, loads\n",
        "\n",
        "def get_unique_union(documents: list[list]):\n",
        "    \"\"\" Unique union of retrieved docs \"\"\"\n",
        "    # Flatten list of lists, and convert each Document to string\n",
        "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
        "    # Get unique documents\n",
        "    unique_docs = list(set(flattened_docs))\n",
        "    # Return\n",
        "    return [loads(doc) for doc in unique_docs]\n",
        "\n",
        "# Retrieve\n",
        "question = \"ما فضيلة الاجتماع على ذكر الله؟\"\n",
        "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
        "docs = retrieval_chain.invoke({\"question\":question})\n",
        "len(docs)\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKEc377hCS66",
        "outputId": "1085bd29-36a0-4a3d-acd6-38a3b76cc036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
            "  warn_beta(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='الشرح: بُعِثَ النبي -صلى الله عليه وسلم- ليُتم مكارم الأخلاق، ولذا فإنه يحث على كل خلق وعمل كريمين، وينهى عن كل قبيح، ومنْ ذلك ما في هذا الحديث من الأشياء التي أمر بها وهي: عيادة المريض التي فيها قيام بحق المسلم، وتَرويح عنه، ودُعاء له، واتباع الجنازة، لما في ذلك من الأجر للتابع والدعاء للمتبوع، والسلام على أهل المقابر والعِظة والاعتبار، وتشميت العاطس إذا حمد الله فيقال له: يرحمك الله. وإبرار قسم المقسم إذا دعاك لشيء وليس عليك ضرر فتبر قسمه، لئلا تُحوجه إلى التكفير عن يمينه، ولتجيب دعوته وتجبر خاطِرَهُ، ونصر المظلوم من ظالمه لما فيه من رد الظلم، ودفع المعتدي وكفه عن الشر، والنهي عن المنكر، وإجابة من دعاك، لأنَّ في ذلك تقريبا بين القلوب وتصفية النفوس، وفي الامتناع الوحشة والتنافر.\\nفإن كانت الدعوة لزواج فالإجابة واجبة، وإن كانت لغيره فمستحبة، و إفشاء السلام، وهو إعلانه وإظهاره لكل أحد، وهو أداء للسنة، ودعاء للمسلمين من بعضهم لبعض، وسبب لجلب المودة.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='والإثم ما تردد في النفس، فهو كالشبهة تردَّدُ في النفس فمن الورع تركها والابتعاد عنها، حماية للنفس من الوقوع في الحرام.\\nفالورع ترك ذلك كله، والاتكاء على ما اطمأن إليه القلب.\\nوأنَّ ما حاك في صدر الإنسان، فهو إثمٌ، وإنْ أفتاه غيرُه بأنَّه ليس بإثمٍ، وهذا إنَّما يكون إذا كان صاحبُه ممَّن شرح صدره بالإيمان، وكان المفتي يُفتي له بمجرَّد ظن أو ميلٍ إلى هوى من غير دليلٍ شرعيٍّ، فأمَّا ما كان مع المفتي به دليلٌ شرعيٌّ، فالواجب على المستفتي الرُّجوعُ إليه، وإنْ لم ينشرح له صدرُه.\\n677 الحديث: عن أبي رقية تميم بن أوس الداري -رضي الله عنه- أن النبي -صلى الله عليه وسلم- قال: «الدين النصيحة» قلنا: لمن؟ قال: «لله، ولكتابه، ولرسوله، ولأئمة المسلمين وعامتهم».'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='الشرح: في هذا الحديث يرشدنا النبي الكريم -صلى الله عليه وسلم- إلى ما يجب علينا معشر المسلمين، بأن نكون متحابين متآلفين متعاملين فيما بيننا معاملة حسنة شرعية تهدينا إلى مكارم الأخلاق، وتبعدنا عن مساوئها، وتذهب عن قلوبنا البغضاء، وتجعل معاملة بعضنا لبعض معاملة سامية خالية من الحسد، والظلم، والغش وغير ذلك مما يستجلب الأذى والتفرق؛ لأن أذية المسلم لأخيه حرام سواء بمال أو بمعاملة أو بيد أو بلسان، كل المسلم على المسلم حرام دمه وماله وعرضه، وإنما العز والشرف بالتقوى.\\n752 الحديث: عن أبي هريرة -رضي الله عنه-: أن رجلًا قال للنبي -صلى الله عليه وآله وسلم-: أوصني، قال لا تَغْضَبْ فردَّدَ مِرارًا، قال لا تَغْضَبْ». \\n الشرح: طلب أحد الصحابة -رضوان الله عليهم- من النبي -صلى الله عليه وسلم- أن يأمره بشيء ينفعه في الدنيا والآخرة، فأمره ألا يغضب، وفي وصيته \"لا تغضب\" دفع لأكثر شرور الإنسان.\\n753 الحديث: عن أبي سعيد الخدري -رضي الله عنه-  أن رسول الله -صلى الله وعليه وسلم- قال: «لا ضَرَرَ ولا ضِرَارَ».'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='الشرح: هذا الحديث من جملة الأحاديث التي فيها الحث على تقوى الله -تعالى-، بفعل أوامره واجتناب نواهيه، وكان هذا الحديث في آخر أيامه -عليه الصلاة والسلام- عندما خطب الناس في حجة الوداع خطبة بليغة وأوصاهم بوصايا كثيرة وذكرهم بما لهم وعليهم ومن جملة ما جاء فيها تقوى الله -تعالى-، حيث قال: (يا أيها الناس اتقوا ربكم) وهذه كقوله -تعالى-: (يَا أَيُّهَا النَّاسُ اتَّقُوا رَبَّكُمُ)، (النساء: من الآية1)، فأمر الرسول -صلى الله عليه وسلم- الناس جميعا أن يتقوا ربهم الذي خلقهم، وأمدهم بنعم لا تُعدُّ ولا تحصى.\\nوفي الحديث الآخر، عن أبي سعيد الخدري -رضي الله عنه- قال: جاء رجل إلى النبي -صلى الله عليه وسلم-، فقال: يا رسول الله أوصني: قال (عليك بتقوى الله، فإنها جماع كل خير..).\\nوقال -صلى الله عليه وسلم-: (أكثر ما يدخل الناس الجنة تقوى الله وحسن الخلق).\\nوقوله: (وصلوا خمسكم) أي: صلوا الصلوات الخمس التي فرضها الله -عز وجل- على رسوله -صلى الله عليه وسلم-، فإن أول ما يحاسب عليه العبد يوم القيامة صلاته.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='الشرح: قوله -عليه الصلاة والسلام-: \"والذي نفسي بيده\" هذا قسم، يقسم فيه النبي -صلى الله عليه وسلم- بالله؛ لأنه هو الذي أَنْفُسُ العباد بيده -جل وعلا-، يهديها إن شاء، ويضلها إن شاء، ويميتها إن شاء، ويبقيها إن شاء، فالأنفس بيد الله هداية وضلالة، وإحياء وإماتة وتصرفًا وتدبيرًا في كل شيء، كما قال الله -تبارك وتعالى-: (ونفس وما سواها، فألهمها فجورها وتقواها)، فالأنفس بيد الله وحده؛ ولهذا أقسم النبي -صلى الله عليه وسلم-، وكان يقسم كثيرًا بهذا القسم: (والذي نفسي بيده)، وأحيانًا يقول: \"والذي نفس محمد بيده\"؛ لأن نفس محمد -صلى الله عليه وسلم- أطيب الأنفس، فأقسم بها؛ لكونها أطيب الأنفس.\\nثم ذكر المقسم عليه، وهو أن نقوم بالأمر بالمعروف والنهي عن المنكر؛ أو يعمنا الله بعقاب من عنده، حتى ندعوه فلا يستجيب لنا، وهذا بيان لأهمية الأمر بالمعروف كالصلاة والزكاة وأداء الحقوق، وأهمية النهي عن المنكر كالزنى والرب وسائر المحرمات، وذلك بالفعل لمن له سلطة كالأب في بيته ورجال الحسبة والشرطة، أو بالقول الحسن وهذا لكل أحد، أو بالقلب مع مفارقة مكان المنكر، وهذا لمن لا يستطيع الإنكار بالفعل أو بالقول.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='\" ونفس لا تشبع\": أي للحرص على الدنيا الفانية، والطمع والشره وتعلق النفس بالآمال البعيدة .\\n\" ومن دعوة لا يستجاب لها\" :أي أعوذ بالله من أسباب ومقتضيات رد الدعوة ، وعدم إجابتها من الطرد والمقت ، لأن رد الدعاء علامة على رد الداعي ، بخلاف دعوة المؤمن فلا ترد إما أن تستجاب في الدنيا ، أو يدفع الله عنه من البلاء بمثلها ، أو تدخر له في الآخرة ، فدعوة المؤمن لا تضيع أبدًا بخلاف دعوة الكافر ، يقول تعالى: \" وما دعاء الكافرين إلا في ضلال\"\\n1133 الحديث: عن عائشة -رضي الله عنها- أن النبي -صلى الله عليه وسلم- كان إذا أخذ مَضْجَعَهُ نَفَثَ في يديه، وقرأ بالمُعَوِّذَاتِ، ومسح بهما جسده. \\nوفي رواية: أن النبي -صلى الله عليه وسلم- كان إذا أَوَى إلى فِرَاشِهِ كل ليلة جَمَعَ كَفَّيْهِ، ثم نَفَثَ فيهما فقرأ فيهما: «قل هو الله أحد، وقل أعوذ برب الفلق، وقل أعوذ برب الناس» ثم مسح بهما ما استطاع من جسده، يبدأ بهما على رأسه ووجهه، وما أَقْبَلَ من جسده، يفعل ذلك ثلاث مرات.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='الشرح: إن الإيمان ليبلى ويَضْعف في قلب المسلم، ويكون ذلك بسبب الفتور في العبادة أو ارتكاب المعاصي وانغماس النفس في شهواتها، فالإيمان يبلى مثل الثوب الجديد الذي يبلى بطول استخدامه، فأخبرنا النبي صلى الله عليه وسلم أن نسأل الله تعالى أن يجدِّد إيماننا بالدعاء والعمل الصالح والقيام بالفرائض وأعمال التطوع وكثرة الذكر والاستغفار، وأن يزيد إيماننا، والتمثيل أسلوب تعليمي نبوي.\\n2364 الحديث: عَنْ أَنَسٍ رَضِيَ اللَّهُ عَنْهُ، قَالَ: لَأُحَدِّثَنَّكُمْ حَدِيثًا سَمِعْتُهُ مِنْ رَسُولِ اللَّهِ صَلَّى اللهُ عَلَيْهِ وَسَلَّمَ لاَ يُحَدِّثُكُمْ بِهِ أَحَدٌ غَيْرِي: سَمِعْتُ رَسُولَ اللَّهِ صَلَّى اللهُ عَلَيْهِ وَسَلَّمَ يَقُولُ: «إِنَّ مِنْ أَشْرَاطِ السَّاعَةِ أَنْ يُرْفَعَ العِلْمُ، وَيَكْثُرَ الجَهْلُ، وَيَكْثُرَ الزِّنَا، وَيَكْثُرَ شُرْبُ الخَمْرِ، وَيَقِلَّ الرِّجَالُ، وَيَكْثُرَ النِّسَاءُ حَتَّى يَكُونَ لِخَمْسِينَ امْرَأَةً القَيِّمُ الوَاحِدُ».'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='فهذه الكلمات بهذه المعاني العظيمة هي مما يبقى أثره ونفعه للمؤمن بعد موته.\\n982 الحديث: عن عبد الله بن عمر -رضي الله عنهما- مرفوعاً: «الْحَيَاء مِنْ الْإِيمَانِ». \\n الشرح: الحياء من الإيمان لأن المستحيي يُقْلِع بحيائه عن المعاصي، ويقوم بالواجبات، وهذا من تأثير الإيمان بالله -تعالى- إذا امتلاْ  به القلب، فإنه يمنع صاحبه من المعاصي ويحثه على الواجبات،\\nفصار الحياء بمنزلة الإيمان، من حيث أثر فائدته على العبد.\\n983 الحديث: عن أنس بن مالك -رضي الله عنه- عن النبي -صلى الله عليه وسلم-قال: «الدعاء بين الأذان والإقامة لا يرد». \\n الشرح: يدل هذا الحديث على فضل الدعاء بين الأذان والإقامة، فمن أُلهِم الدعاء ووفق له فقد أُريد به الخير وأُرِيدتْ له الإجابة.\\nويستحب الدعاء في هذا الوقت؛ لأن الإنسان ما دام ينتظر الصلاة فهو في صلاة، والصلاة موطن لاستجابة الدعاء؛ لأن العبد يناجي ربه فيها، فهذا الوقت على المسلم أن يجتهد فيه بالدعاء.\\n984 الحديث: nan \\n الشرح: nan'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='وأما الثالث -وهو الحق المشترك- فقوله: \"إيتاء الزكاة\" يعني: إعطاءها لمستحقها.\\nوأما الثاني -وهو حق الآدمي- فقوله: \"النصح لكل مسلم\"، أي: أن ينصح لكل مسلم: قريب أو بعيد، صغير أو كبير، ذكر أو أنثى.\\nوكيفية النصح لكل مسلم هي ما ذكره في حديث أنس -رضي الله عنه-: \"لا يؤمن أحدكم حتى يحب لأخيه ما يحب لنفسه\" هذه هي النصيحة أن تحب لإخوانك ما تحب لنفسك، بحيث يسرك ما يسرهم، ويسوءك ما يسوؤهم، وتعاملهم بما تحب أن يعاملوك به، وهذا الباب واسعُ كبيرُ جدًّا.\\n421 الحديث: عن جابر بن عبد الله الأنصاري -رضي الله عنهما- قال: «كَانَ -صلى الله عليه وسلم- يُصَلِّي الظُّهْرَ بِالهَاجِرَة، والعَصرَ والشَّمسُ نَقِيَّة، والمَغرِب إِذَا وَجَبَت، والعِشَاء أَحيَانًا وأَحيَانًا: إِذَا رَآهُم اجتَمَعُوا عَجَّل، وَإِذَا رَآهُم أَبْطَئُوا أًخَّر، والصُّبحُ كان النبي -صلى الله عليه وسلم- يُصَلِّيهَا بِغَلَس». \\n الشرح: في هذا الحديث بيان الأفضل في الوقت، لأداء الصلوات الخمس.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='الشرح: عرض النبي -صلى الله عليه وسلم- على  أصحابه عرضًا، وهو يعلم ماذا سيقولون في جوابه، وهذا من حسن تعليمه عليه الصلاة والسلام، أنه أحيانا يعرض المسائل عرضا، حتى ينتبه الإنسان لذلك، ويعرف ماذا سيلقى إليه، قال: ألا أدلكم على ما يمحو الله به الخطايا، ويرفع به الدرجات؟.\\nقالوا: بلى يا رسول الله، يعني: أخبرنا فإننا نود أن تخبرنا بما نرفع به الدرجات ونمحو به الخطايا، قال:\\nأولا: إتمام الوضوء في حال كراهة النفس لذلك، مثل أيام الشتاء؛ لأن أيام الشتاء يكون الماء فيها باردا، فإذا أتم الإنسان وضوءه مع هذه المشقة، دل هذا على كمال الإيمان، فيرفع الله بذلك درجات العبد ويحط عنه خطيئته.\\nثانيا:  أن يقصد الإنسان المساجد، حيث شرع له إتيانهن، وذلك في الصلوات الخمس، ولو بَعُد المسجد.\\nثالثا: أن يشتاق الإنسان إلى الصلوات، كلما فرغ من صلاة، فقلبه متعلق بالصلاة الأخرى ينتظرها، فإن هذا يدل على إيمانه ومحبته وشوقه لهذه الصلوات العظيمة. \\nفإذا كان ينتظر الصلاة بعد الصلاة، فإن هذا مما يرفع الله به الدرجات، ويكفر به الخطايا.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='ولما وضع الرب سبحانه وتعالى كفه بين كتفي النبي صلى الله عليه وسلم انكشف له كل شيء وعرف الجواب فقال: يتحدثون ويتناقشون ويختصمون في الخصال التي من شأنها أن تُكَفِّر الخطيئة، واختصامهم عبارة عن تبادرهم إلى إثبات تلك الأعمال والصعود بها إلى السماء، أو تحدثهم في فضلها وشرفها، وهذه الخصال هي: المشي إلى صلاة الجماعة، والجلوس في المسجد بعد انتهاء الصلوات للذكر والقراءة وسماع العلم وتعليمه، وإتمام الوضوء وإبلاغه مواضعه الشرعية في الحالات التي تكره النفس فيها الوضوء كالبرد الشديد.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='أو لما اجتمع فيها من فصاحة المباني وبلاغة المعاني، أو لأنها تثنى على مرور الزمان وتتكرر فلا تنقطع وتدرس فلا تندرس، أو لأن فوائدها تتجدد حالاً فحالاً إذ لا منتهى لها، أو جمع مثناه من الثناء لاشتمالها على ما هو ثناء على اللّه تعالى، فكأنها تثنى عليه بأسمائه الحسنى وصفاته، أو من الثنايا لأن اللّه استثناها لهذه الأمة، وغير ذلك، قوله: \"والقرآن العظيم\"، أي: وهي المسماة بذلك أيضاً، قوله: \"الذي أوتيته\"، أي: أعطيته، وتسميتها بالقرآن العظيم لجمعها سائر ما يتعلق بالموجودات دنيا وأخرى وأحكاماً وعقائد.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='الشرح: هذا الحديث من الأحاديث التي تدل على فضيلة الاجتماع على ذكر الله -عز وجل-، وهو ما رواه أبو سعيد الخدري عن معاوية -رضي الله عنهما- أنه خرج على حلقة في المسجد فسألهم على أي شيء اجتمعوا، فقالوا: نذكر الله، فاستحلفهم -رضي الله عنه- أنهم ما أرادوا بجلوسهم واجتماعهم إلا الذكر، فحلفوا له، ثم قال لهم: إني لم أستحلفكم تهمة لكم وشكًّا في صدقكم، ولكني رأيت النبي -صلى الله عليه وسلم- خرج على قوم وذكر مثله، وأخبرهم أن الله -عز وجل- يباهي بهم الملائكة، فيقول مثلا: انظروا إلى عبادي اجتمعوا على ذكري، وما أشبه ذلك، مما فيه المباهاة، ولكن ليس هذا الاجتماع أن يجتمعوا على الذكر بصوت واحد، ولكن يذكرون أي شيء يذكرهم بالله -تعالى- من موعظة وذكرى أو يتذكرون نعمة الله عليهم بما أنعم عليهم من نعمة الإسلام وعافية البدن والأمن، وما أشبه ذلك، فإن ذكر نعمة الله من ذكر الله -عز وجل-، فيكون في هذا دليل على فضل جلوس الناس ليتذاكروا نعمة الله عليهم.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='586 الحديث: عن أبي هريرة -رضي الله عنه- قال: قال رسول الله -صلى الله عليه وسلم-: «ما من قوم يقومون من مجلس لا يذكرون الله -تعالى- فيه، إلا قاموا عن مثل جيفة حمار، وكان لهم حسرة». \\n الشرح: معنى الحديث: أن من جلسوا في مجلس لم يذكروا الله -تعالى- فيه فحالهم كمثل حال الذي يجلس في مائدة ضيافتها جِيفَةُ حمار، التي هي غاية في النتانة والقذارة، ويقوم عن ذلك المجلس كمن يقوم عن هذه الجيفة، وهذا مثال للتفريط في ذكر الله، فيتندمون أشد الندم على ما فرطوا في أوقاتهم وأضاعوها فيما لا نفع فيه. \\nفينبغي على المسلمين: أن يحرصوا كل الحرص على أن تكون مجالسهم طاعة وعبادة وأن يفروا من مجالس اللهو كما يفرون من النتانة والقذارة، فإن الإنسان مسؤول عن أوقاته، ومحاسب عليها، فإن كان خيرًا فخير وإن كان شرًا فشر.\\n587 الحديث: عن جابر-رضي الله عنه- قال: قال رسول الله -صلى الله عليه وسلم-: «ما من مسلم يَغرس غَرسا إلا كان ما أُكل منه له صدقة، وما سُرق منه له صدقة، ولا يَرْزَؤُهُ أحد إلا كان له صدقة».')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Decomposing the question into sub questions:\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Decomposition\n",
        "template = \"\"\"أنت مساعد مفيد يقوم بإنشاء أسئلة فرعية متعددة تتعلق بسؤال الإدخال.\n",
        "الهدف هو تقسيم المدخلات إلى مجموعة من المشكلات الفرعية.الأسئلة الفرعية التي يمكن أن تكون إجابات منفصلة.\n",
        "إنشاء استعلامات بحث متعددة تتعلق بـ: {question}\n",
        "الجواب:\"\"\"\n",
        "prompt_decomposition = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "FnhvQHb1C01z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Chain\n",
        "generate_queries_decomposition = ( prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
        "\n",
        "# Run\n",
        "question = \"ما مصير القاتل و المقتول من المسلمان اذا التقى بسيفهما ؟\"\n",
        "questions = generate_queries_decomposition.invoke({\"question\":question})\n",
        "questions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05G5woHWGbgP",
        "outputId": "cc3a8a0e-0d99-4739-c32d-4fbd45117782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. هل كان القاتل يعتدي على المقتول بدون سبب مبرر؟',\n",
              " '2. هل كان القاتل يدافع عن نفسه أو عن شخص آخر عندما قتل المسلمان؟',\n",
              " '3. هل كان القاتل يعاني من اضطراب نفسي أو عقلي يمكن أن يؤثر على تصرفاته؟',\n",
              " '4. هل كانت هناك ظروف خاصة تجعل من القتل غير مقصود أو غير متعمد؟',\n",
              " '5. هل كان هناك توافق بين القاتل وأسرة المقتول بشأن مصيرهما بعد الحادثة؟']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt\n",
        "template = \"\"\"هذا هو السؤال الذي تحتاج إلى الإجابة عليه:\n",
        "\n",
        "\\n --- \\n {question} \\n --- \\n\n",
        "\n",
        "فيما يلي أي سؤال خلفي متاح + أزواج الإجابات:\n",
        "\n",
        "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
        "\n",
        "فيما يلي سياق إضافي ذو صلة بالسؤال:\n",
        "\n",
        "\\n --- \\n {context} \\n --- \\n\n",
        "\n",
        "استخدم السياق أعلاه وأي سؤال في الخلفية + أزواج الإجابات للإجابة على السؤال:\n",
        " \\n {question}\n",
        "\"\"\"\n",
        "\n",
        "decomposition_prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "oBQNleVBHVTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def format_qa_pair(question, answer):\n",
        "    \"\"\"Format Q and A pair\"\"\"\n",
        "\n",
        "    formatted_string = \"\"\n",
        "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
        "    return formatted_string.strip()\n",
        "\n",
        "# llm\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "q_a_pairs = \"\"\n",
        "for q in questions:\n",
        "\n",
        "    rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever,\n",
        "     \"question\": itemgetter(\"question\"),\n",
        "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")}\n",
        "    | decomposition_prompt\n",
        "    | llm\n",
        "    | StrOutputParser())\n",
        "\n",
        "    answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
        "    q_a_pair = format_qa_pair(q,answer)\n",
        "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR_IpeByIq7q",
        "outputId": "42d87145-f394-48cb-bdaf-7a86a3f3bfd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-29ATtbTIt9J",
        "outputId": "77657646-9722-4756-b885-17e5fda610de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'الإجابة: لا، لم يكن هناك توافق بين القاتل وأسرة المقتول بشأن مصيرهما بعد الحادثة، حيث يشير السياق إلى أن القاتل كان يعتدي على المقتول دفاعًا عن نفسه أو ماله بشكل مبرر، ولم يكن هناك اتفاق مسبق بينهما بخصوص مصيرهما بعد الحادثة.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Now will try to perform step back question\n",
        "# Few Shot Examples\n",
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "openai = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "examples = [\n",
        "    {\n",
        "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
        "        \"output\": \"what can the members of The Police do?\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
        "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
        "    },\n",
        "]\n",
        "# We now transform these to example messages\n",
        "example_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"ai\", \"{output}\"),\n",
        "    ]\n",
        ")\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples,\n",
        "\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"أنت خبير في المعرفة العالمية. مهمتك هي التراجع وإعادة صياغة السؤال إلى سؤال رجعي أكثر عمومية، وهو ما يسهل الإجابة عليه. وفيما يلي بعض الأمثلة على ذلك:\"\"\",\n",
        "        ),\n",
        "        # Few shot examples\n",
        "        few_shot_prompt,\n",
        "        # New question\n",
        "        (\"user\", \"{question}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7squ_bOoIxn_",
        "outputId": "dc7b151e-9ea8-459f-9146-fa61065f8190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_queries_step_back = prompt | ChatOpenAI(temperature=0) | StrOutputParser()\n",
        "question = \"ما فضيلة الاجتماع على ذكر الله\"\n",
        "generate_queries_step_back.invoke({\"question\": question, \"input\" : question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "i3NbWzmRLaVF",
        "outputId": "22723056-418f-4406-83ae-34e9d8c7da2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ما هي فوائد الاجتماع على ذكر الله؟'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "# Response prompt\n",
        "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
        "\n",
        "# {normal_context}\n",
        "# {step_back_context}\n",
        "\n",
        "# Original Question: {question}\n",
        "# Answer:\"\"\"\n",
        "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
        "\n",
        "chain = (\n",
        "    {\n",
        "        # Retrieve context using the normal question\n",
        "       \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
        "        # Retrieve context using the step-back question\n",
        "        \"step_back_context\": generate_queries_step_back | retriever,\n",
        "        # Pass on the question\n",
        "        \"question\": lambda x: x[\"question\"],\n",
        "    }\n",
        "    | response_prompt\n",
        "    | ChatOpenAI(temperature=0)\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain.invoke({\"question\": question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "JPmd5_OFLyqC",
        "outputId": "215ada5f-be94-417b-920a-ddf3cb6168bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'فضيلة الاجتماع على ذكر الله تعالى تتجلى في عدة جوانب وفوائد. أولاً، يعتبر الاجتماع على ذكر الله من الأعمال الصالحة التي تقرب الإنسان إلى الله وتزيد من درجاته في الدنيا والآخرة. ثانياً، يعمل الاجتماع على ذكر الله على تعزيز الروابط الاجتماعية بين المسلمين وتعزيز الأخوة والمحبة بينهم. ثالثاً، يساهم الاجتماع على ذكر الله في تعزيز الوعي الديني والروحي للأفراد وتحفيزهم على الاستمرار في الطاعات والابتعاد عن المعاصي.\\n\\nالحديث الذي ذكرته يشير إلى أهمية الاجتماع على ذكر الله وأنه يعد من أعظم الأعمال الصالحة التي يمكن للإنسان أن يقوم بها. يجب على المسلمين أن يحرصوا على الاجتماع على ذكر الله بانتظام وباستمرار، سواء كان ذلك في المساجد أو في البيوت أو في أي مكان آخر. وينبغي لهم أن يتذكروا نعم الله عليهم ويحمدوه على كل ما منّ بهم، مما يعزز الشكر والامتنان لله تعالى.\\n\\nبالإضافة إلى ذلك، يجب على المسلمين أن يحرصوا على تقوى الله والالتزام بأوامره واجتناب نواهيه، كما جاء في الحديث الآخر الذي ذكرته. تقوى الله هي جوهر الدين ومفتاح النجاح في الدنيا والآخرة، وهي التي تجعل الإنسان يتقرب إلى الله ويحصل على رضاه ومغفرته.\\n\\nباختصار، فضيلة الاجتماع على ذكر الله تعالى تتمثل في تعزيز الروابط الاجتماعية، تحقيق الوحدة والتآخي بين المسلمين، تعزيز الوعي الديني والروحي، وتحقيق الشكر والامتنان لنعم الله. والله أعلى وأعلم.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## HyDE Technique\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# HyDE document genration\n",
        "template = \"\"\"يرجى كتابة فقرة ورقة علمية للإجابة على السؤال\n",
        "السؤال: {question}\n",
        "\"\"\"\n",
        "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "generate_docs_for_retrieval = (\n",
        "    prompt_hyde | ChatOpenAI(temperature=0) | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Run\n",
        "question = \"ماذا اشترط الرسول في صوم يوم الجمعة ؟\"\n",
        "generate_docs_for_retrieval.invoke({\"question\":question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "NUfMjhwKQ9q2",
        "outputId": "cfa4091f-c6df-40ca-da64-f817e16ba1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'في الإسلام، يعتبر يوم الجمعة يومًا مميزًا ومباركًا، حيث يُشترط على المسلمين صيامه وإقامة صلاة الجمعة فيه. وقد ورد في السنة النبوية أن الرسول محمد صلى الله عليه وسلم أشترط في صوم يوم الجمعة أن يصوم اليوم الذي قبله أو الذي يأتي بعده، وذلك لتمييز يوم الجمعة عن غيره من الأيام. ويعتبر صوم يوم الجمعة من الأعمال النافلة المستحبة في الإسلام، ويُعظم أجره وثوابه في عين الله.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve\n",
        "retrieval_chain = generate_docs_for_retrieval | retriever\n",
        "retireved_docs = retrieval_chain.invoke({\"question\":question})\n",
        "retireved_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RqMj2J2UXgO",
        "outputId": "07fc36f6-6117-4591-8b60-277be6f595f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='وبهذا أخذ جمهور العلماء، ومنهم الأئمة الأربعة، ومن أدلتهم أيضًا حديث مسلم: (من توضأ فأحْسَن الوضوء، ثم أتَى الجُمعة فاسْتَمَع وأنْصَت غُفر له ما بين الجمعة إلى الجمعة وزيادة ثلاثة أيام).\\n1675 الحديث: عن عمرو بن سليم الأنصاري قال: أشهد على أبي سعيد قال: أشهد على رسول الله -صلى الله عليه وسلم- قال: «الغُسْل يوم الجمعة واجِب على كل مُحْتَلِمٍ، وأن يَسْتَنَّ، وأن يَمَسَّ طِيبًا إن وجَد». \\n الشرح: يقول أبو سعيد الخدري -رضي الله عنه-:\" أشهد على رسول الله -صلى الله عليه وسلم-\" أي أخبركم عن النبي -صلى الله عليه وسلم- خبراً أكيداً صادراً عن يقين وعلم قاطع، أنه -صلى الله عليه وسلم- قال: \"الغسل يوم الجمعة واجب على كل محتلم\" أي: الغسل يوم الجمعة متأكد على كل ذكر بالغ من المسلمين مطلقاً، جامع أو لم يجامع، أجنب أو لم يجنب، ويخرجه من الوجوب حديث سمرة بن جندب -رضي الله عنه- مرفوعا: \"من توضأ يوم الجمعة فبها ونعمت، ومن اغتسل فهو أفضل\"، أي: من اكتفى يوم الجمعة بالوضوء فقد أخذ بالرخصة، وأجزأه الوضوء، ونعمت الرخصة، ومن اغتسل، فالغسل أفضل؛ لأنه سنة مستحبة.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='الشرح: يبين النبي -صلى الله عليه وسلم- فضل الاغتسال والتبكير إلى الجمعة، ودرجات الفضل في ذلك، فذكر أن من اغتسل يوم الجمعة قبل الذهاب إلى الصلاة، ثم ذهب إليها في الساعة الأولى، فله أجر من قرب بعيرًا ذبحه وتصدق به تقربًا إلى الله ومن راح بعده في الساعة الثانية فكأنما قرب -أي أهدى- بقرة.\\nومن راح في الساعة الثالثة فكأنما قرب كبشاً ذا قرنين، وغالباً يكون أفضل الأكباش وأحسنها. \\nومن راح في الساعة الرابعة فكأنما قرب دجاجة. \\nومن راح في الساعة الخامسة، فكأنما قرب بيضة.\\nفإذا خرج الإمام للخطبة والصلاة؛ انصرفت الملائكة الموكلون بكتابة القادمين إلى سماع الذكر، فمن أتى بعد انصرافهم، لم يكتب من المقَرِّبين.\\n930 الحديث: عن عبد الله بن عُمر رضي الله عنهما عن رسول الله صلى الله عليه وسلم أنه قال: «من جاء منكم الجمعة فلْيَغْتَسِل». \\n الشرح: الاجتماع لصلاة الجمعة مشهد عظيم، ومجمع كبير من مجامع المسلمين، حيث يأتون لأدائها من أنحاء البلد، التي يسكنونها.\\nومثل هذا المحفل، الذي يظهر فيه شعار الإسلام، وأَبَّهة المسلمين، يكون الآتي إليه على أحسن هيئة، وأطيب رائحة، وأنظف جسم.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='والرواية الثانية: أنهم كانوا يصلون الجمعة مع النبي -صلى الله عليه وسلم- إذا زالت الشمس، ثم يرجعون.\\nاتفق العلماء على أن آخر وقت صلاة الجمعة هو آخر وقت صلاة الظهر، والأولى والأفضل الصلاة بعد الزوال؛ لأنه الغالب من فعل النبي -صلى الله عليه وسلم-؛ ولأنه الوقت المجمع عليه بين العلماء إلا أن يكون ثَمَّ حاجة؛ من حر شديد، وليس عندهم ما يستظلون به، أو يريدون الخروج لجهاد قبل الزوال، فلا بأس من صلاتها قبل الزوال قريبًا منه.\\n934 الحديث: عن عبد الله بن عُمر بن الخطاب -رضي الله عنهما- قال: «كان النبي -صلى الله عليه وسلم- يخطب خطبتين يقعد بينهما» وفي رواية لجابر - رضي الله عنه-: «كان رسول الله -صلى الله عليه وسلم- يَخْطُبُ خُطْبَتَيْنِ وهو قائم، يفصل بينهما بجلوس». \\n الشرح: يوم الجمعة مجمع كبير شامل لأهل البلد كلهم، ولذا كان النبي -صلى الله عليه وسلم- من حكمته يخطب الناس يوم الجمعة خطبتين، يوجههم فيهما إلى الخير، ويزجرهم عن الشر وكان يأتي بالخطبتين وهو قائم على المنبر؛ ليكون أبلغ في تعليمهم ووعظهم، ولما في القيام من إظهار قوة الإسلام وأبهته.'),\n",
              " Document(metadata={'source': 'hadeeth_ds_final_file.txt'}, page_content='713 الحديث: عن أبي هريرة -رضي الله عنه- عن النبي -صلى الله عليه وسلم- قال: «مَنْ نَسِيَ وَهُوَ صَائِمٌ فأَكل أو شَرِب، فَلْيُتِمَّ صَوْمَهُ، فَإِنَّمَا أَطْعَمَهُ الله وَسَقَاهُ». \\n الشرح: بُنيت الشريعة الإسلامية على اليسر والسهولة، والتكليف بقدر الطاقة، وعدم المؤاخذة بما يخرج عن الاستطاعة أو الاختيار.\\nومن ذلك : أن من أكل أو شرب، أو فعل مفطراً غيرهما في نهار رمضان، أو غيره من الصيام، فَلْيُتِمَّ صَومه، فإنه صحيح؛ لأن هذا ليس باختياره، فما فعله الإنسان ناسياً من غير نية فإنه لا يقدح في صومه ولا يؤثر فيه وإنما هو من الله الذي أطعمه وسقاه.\\n714 الحديث: عن محمد بن عباد بن جعفر قال: «سألت جابر بن عبد الله -رضي الله عنهما-: أَنَهَى النبي -صلى الله عليه وسلم- عن صوم يوم الجمعة ؟ قال: نعم».\\nوفي رواية: «وَرَبِّ الْكَعْبَة». \\n الشرح: لما كان يوم الجمعة يوم عيد للمسلمين، نهى الشارع عن تخصيصه بصيام أو قيام، إلا أن يصوم يوماً معه قبله أو بعده أو يكون ضمن صوم معتاد، ولئلا يظن العامة أيضاً تخصيص يوم الجمعة بزيادة عبادة على غيره واجبة.')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG\n",
        "template = \"\"\"ستخدم الأجزاء التالية من السياق المتكونة من حديث و شرح  للإجابة على السؤال التالي في النهاية\n",
        "احرص على ان تكون كلامات اجابتك متواجدة في نص الحديث او شرحه.\n",
        ".ستند الى السياق جيدا\n",
        ".قد تكون الاجابة تكملتا للسياق او متضمنة في معناه . اذكر الحديث او النص الدقيق اذا انطلب في السؤال\n",
        "إذا كنت لا تعرف الإجابة، قل فقط أنك لا تعرف، ولا تحاول اختلاق إجابة.\n",
        "اجعل الإجابة مختصرة و موجزة قدر الإمكان. قل دائمًا \"شكرًا على السؤال!\" في نهاية الجواب.\n",
        "السياق: {context}\n",
        "السؤال: {question}\n",
        "الجواب المفيد:\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "final_rag_chain = (\n",
        "    prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "question = \"ماذا اشترط الرسول في صوم يوم الجمعة مع ذكر الدليل ؟\"\n",
        "final_rag_chain.invoke({\"context\":retireved_docs,\"question\":question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "1FSOnxB_VuZ-",
        "outputId": "d34c215f-cf70-4266-c959-602abc70334c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'اشترط الرسول في صوم يوم الجمعة أن يكون ضمن صوم معتاد، وذلك بناءً على حديث جابر بن عبد الله -رضي الله عنهما- الذي نقل فيه أن النبي -صلى الله عليه وسلم- نهى عن صوم يوم الجمعة. شكرًا على السؤال!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Applying Semantic Routing\n",
        "from langchain.utils.math import cosine_similarity\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "bmSlIWafYf2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Five Different Prompts\n",
        "prompt_completion_template = \"\"\"استخدم الأجزاء التالية من السياق المتكونة من حديث و شرح  للإجابة على السؤال التالي في النهاية\n",
        "احرص على ان تكون كلامات اجابتك متواجدة في نص الحديث او شرحه.\n",
        "استند الى السياق جيدا.\n",
        ".قد تكون الاجابة تكملتا للسياق او متضمنة في معناه . اذكر الحديث او النص الدقيق اذا انطلب في السؤال.\n",
        "إذا كنت لا تعرف الإجابة، قل فقط أنك لا تعرف، ولا تحاول اختلاق إجابة.\n",
        "قل دائمًا \"شكرًا على السؤال!\n",
        " \"\"\"\n",
        "through_explaination_template = \"\"\"\n",
        "انت بارع في علوم الاحاديث الإسلامية و شرحها.\n",
        "انت ذكي وقادر على الإجابة على اسالة المستخدم المستخلصة من شروحات الاحاديث.\n",
        "قد يكون السؤال عن حكم, فضل, اجر, موقف, امر, صفة للرسول, معاني, دعاء, وغيره.\n",
        "السياق: {context}\n",
        "السؤال:\n",
        "{query}\"\"\" + prompt_completion_template\n",
        "\n",
        "Hadeeth_completion_template= \"\"\"\n",
        "لديك العديد من نصوص الاحاديث الإسلامية الكاملة.\n",
        "هؤلاء الاحاديث مخزنون لديك و انت قادر على اكمال أي حديث سيطلبه المستخدم منك.\n",
        "سيقوم المستخدم بكتابة جزء من الحديث وسيكون عليك ذكر الحديث كاملا.\n",
        "السياق: {context}\n",
        "السؤال:\n",
        "{query}\"\"\" + prompt_completion_template\n",
        "\n",
        "hadeeth_metioning_template= \"\"\"\n",
        "انت بارع في فهم نصوص الاحاديث من خلال شروحها واستنباط المعلومات المفيدة منها من احكام و ادعية وغيرها.\n",
        "سيقوم المستخدم بذكر معلومة او فائدة من احد شروح الاحاديث و سيكون عليك ذكر الحديث كاملا.\n",
        "السياق: {context}\n",
        "السؤال:\n",
        "{query}\"\"\" + prompt_completion_template\n",
        "\n",
        "hadeeth_explaining_template = \"\"\"\n",
        "لديك مجموعة من الاحاديث مع شروحاتها.\n",
        "سيقوم المستخدم باعطائك احد الاحاديث وسيكون عليك ذكر شرحها فقط.\n",
        "السياق: {context}\n",
        "السؤال:\n",
        "{query}\"\"\" + prompt_completion_template\n",
        "\n",
        "hybrid_question_template = \"\"\"\n",
        "\n",
        "السياق: {context}\n",
        "السؤال:\n",
        "{query}\"\"\" + prompt_completion_template\n",
        "\n",
        "# Embed prompts\n",
        "embeddings = OpenAIEmbeddings()\n",
        "prompt_templates = [\"\"\"templates  \"\"\"]\n",
        "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
        "\n",
        "# Route question to prompt\n",
        "def prompt_router(input):\n",
        "  \"\"\" define with prompt to use \"\"\"\n",
        "\n",
        "# Next: Do the answer chain\n",
        "\n",
        "chain = (\n",
        "     prompt_router\n",
        "    | ChatOpenAI()\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(chain.invoke({\"query\" : \"What's a black hole\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "uvtJguyi7h9z",
        "outputId": "ccc6aa93-e162-43e3-e1ec-7c85cd960869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'physics_template' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-bd2c87adfb09>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Embed prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprompt_templates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mphysics_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_template\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprompt_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_templates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'physics_template' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9wqcDYTrEJvc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}